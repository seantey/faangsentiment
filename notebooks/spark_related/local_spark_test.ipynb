{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data from DynamoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from boto3.dynamodb.conditions import Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'test_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamodb = boto3.resource('dynamodb')\n",
    "table = dynamodb.Table(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_analysis_window = '2020-07-14_Hour=14'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = table.query(\n",
    "#     KeyConditionExpression=Key('analysis_window').eq(target_analysis_window)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = table.scan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a list of dictionaries where\n",
    "# the keys of each dictionary is a key/column in the DynamoDB table\n",
    "news_data = response['Items']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start spark and parallelize the data for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "            .appName(\"SparkTest\") # Set app name\n",
    "            .master(\"local[4]\") # Run locally with 4 cores\n",
    "            .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean-cx1/Documents/personal_projects/faangsentiment/notebooks/faangs_venv/lib/python3.7/site-packages/pyspark/sql/session.py:366: UserWarning: Using RDD of dict to inferSchema is deprecated. Use pyspark.sql.Row instead\n",
      "  warnings.warn(\"Using RDD of dict to inferSchema is deprecated. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- analysis_window: string (nullable = true)\n",
      " |-- api_success_utc_str: string (nullable = true)\n",
      " |-- api_success_utc_ts: decimal(38,18) (nullable = true)\n",
      " |-- news_content: string (nullable = true)\n",
      " |-- news_link: string (nullable = true)\n",
      " |-- news_publisher: string (nullable = true)\n",
      " |-- news_timestamp: decimal(38,18) (nullable = true)\n",
      " |-- news_title: string (nullable = true)\n",
      " |-- source_api: string (nullable = true)\n",
      " |-- symb_id_source: string (nullable = true)\n",
      " |-- t_symb: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This method throws deprecated function warning\n",
    "#Convert list to RDD\n",
    "news_rdd = spark.sparkContext.parallelize(news_data)\n",
    "#Create data frame\n",
    "news_df = spark.createDataFrame(news_rdd)\n",
    "\n",
    "# Alternative method which doesn't throw deprecated warning:\n",
    "# https://kontext.tech/column/spark/366/convert-python-dictionary-list-to-pyspark-dataframe\n",
    "# from pyspark.sql import Row\n",
    "# news_df = spark.createDataFrame([Row(**i) for i in news_data])\n",
    "# BUT! This method throws an error with .rdd.flatMap(lambda x: x).collect()\n",
    "# java.lang.IllegalStateException: Input row doesn't have expected number of values required by the schema. \n",
    "# 11 fields are required while 10 values are provided.\n",
    "# However, we don't usually collect until the end of the pipeline.\n",
    "\n",
    "news_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple News adds new audio features, including a daily briefing, alongside expanded local coverage'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data[0]['news_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = news_df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/38610559/\n",
    "content_list = news_df.select(\"news_content\").rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from transformers import pipeline\n",
    "from multiprocessing import cpu_count\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalysisPipeline:\n",
    "    def __init__(self):\n",
    "        # Note that the transformers pipelines can take list of strings as input\n",
    "        # instead of just one string.\n",
    "        self.summarizer_pipeline = pipeline(\"summarization\")\n",
    "#         self.sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "        \n",
    "        # multiprocessing core count heuristic from \n",
    "        # comment in https://stackoverflow.com/questions/20886565/\n",
    "        self.pool_cores = cpu_count()-1 or 1\n",
    "        \n",
    "    def strip_html(self,input_string):\n",
    "        \"\"\"\n",
    "        Strips any HTML tags from a string\n",
    "        \"\"\" \n",
    "        \n",
    "        cleaned_text = BeautifulSoup(input_string).text\n",
    "        \n",
    "        return cleaned_text\n",
    "    \n",
    "    def strip_html_multi(self, input_string_list):\n",
    "                \n",
    "        # Make sure input is a list, or if it's one string\n",
    "        # convert to list.\n",
    "        if type(input_string_list) is not list:\n",
    "            input_string_list = list(input_string_list)     \n",
    "\n",
    "        # TODO may want to initialize and destroy pool somwhere else\n",
    "        # Or it might not matter too much given this function is only\n",
    "        # called once per spark job / AWS EMR startup\n",
    "        p = 2\n",
    "        with Pool(processes=p) as pool:\n",
    "            chunksize = 3\n",
    "            no_html_text = pool.map(self.strip_html, input_string_list, chunksize)        \n",
    "        \n",
    "        return no_html_text\n",
    "    \n",
    "    def raw_text_to_sentiment(self,input_string):\n",
    "        \"\"\"\n",
    "        Takes a list of strings or just one regular string and runs it\n",
    "        through a pipeline to get the positive/negative label and the\n",
    "        respective scores.\n",
    "        \n",
    "        Pipeline consists of:\n",
    "        (1) Removing HTML if present\n",
    "        (2) Summarizing the news articles\n",
    "        (3) Calculating a sentiment score and label (Positive or Negative)\n",
    "        \n",
    "        Returns a list of dictionaries with label and score as keys.\n",
    "        \"\"\"\n",
    "\n",
    "#         no_html_text = self.strip_html_multi(input_string)\n",
    "        \n",
    "        news_summary = self.summarizer_pipeline(no_html_text, \n",
    "                                                max_length=300, \n",
    "                                                min_length=30)[0]['summary_text']\n",
    "#         sentiment_scores = self.sentiment_pipeline(summary_news)\n",
    "\n",
    "        return news_summary\n",
    "#         return sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_pipe = SentimentAnalysisPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = s_pipe.raw_text_to_sentiment(content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_summarizer_pipeline = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_summarizer_pipeline(content_list[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html_test(input_string):\n",
    "    \"\"\"\n",
    "    Strips any HTML tags from a list of strings with multiple processes.\n",
    "    \"\"\"   \n",
    "\n",
    "    cleaned_text = BeautifulSoup(input_string).text\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 2\n",
    "with Pool(processes=p) as pool:\n",
    "    chunksize = 3\n",
    "    no_html_text = pool.map(strip_html_test, content_list, chunksize)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html(input_string):\n",
    "    cleaned_text = BeautifulSoup(input_string).text\n",
    "    return cleaned_text\n",
    "\n",
    "# Define Spark UDF for parallel processing\n",
    "strip_html_udf = udf(strip_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = drop_na_df.select('news_content', strip_html_udf('news_content').alias('clean_content'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1431475249884f3793a720b18d3ae92e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1578.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b568151cafeb4aa1ba5f531271de6d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898822.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440cf793b7554f9d852d3619a8d77b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab65dc3ddd804088bb92af24f18c16c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=26.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029a4b1b591f400f96213eefc99e39d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1222317369.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE = \"\"\"\n",
    "\n",
    "WhatsApp was briefly down Tuesday, with users unable to send or receive messages on the Facebook-owned end-to-end encrypted messaging app.\n",
    "\n",
    "Affected users may have seen that WhatsApp was \"connecting\" to the service when trying to send a message. The outage started at about 4 p.m. ET but appeared to be working again by 4:30 p.m. ET.\n",
    "\n",
    "WhatsApp failing to connect to its servers. (Image Credits: TechCrunch)\n",
    "\n",
    "When reached, a Facebook spokesperson confirmed the outage but didn't divulge details.\n",
    "\n",
    "\"We're aware that some people are currently having trouble sending messages and we're working to restore WhatsApp for everyone as quickly as possible,\" the spokesperson said.\n",
    "\n",
    "WhatsApp hit the 2 billion user mark earlier this year. Facebook bought WhatsApp for $19 billion in 2014 in what became one of the social media giant's biggest purchases.\n",
    "\n",
    "Updated with comment from Facebook.\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_article = strip_html(ARTICLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nWhatsApp was briefly down Tuesday, with users unable to send or receive messages on the Facebook-owned end-to-end encrypted messaging app.\\n\\nAffected users may have seen that WhatsApp was \"connecting\" to the service when trying to send a message. The outage started at about 4 p.m. ET but appeared to be working again by 4:30 p.m. ET.\\n\\nWhatsApp failing to connect to its servers. (Image Credits: TechCrunch)\\n\\nWhen reached, a Facebook spokesperson confirmed the outage but didn\\'t divulge details.\\n\\n\"We\\'re aware that some people are currently having trouble sending messages and we\\'re working to restore WhatsApp for everyone as quickly as possible,\" the spokesperson said.\\n\\nWhatsApp hit the 2 billion user mark earlier this year. Facebook bought WhatsApp for $19 billion in 2014 in what became one of the social media giant\\'s biggest purchases.\\n\\nUpdated with comment from Facebook.\\n\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 300, but you input_length is only 204. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    }
   ],
   "source": [
    "summary_news = summarizer(clean_article, max_length=300, min_length=30)[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Facebook bought WhatsApp for $19 billion in 2014 . The end-to-end encrypted messaging app was briefly down at about 4 p.m. ET Tuesday . Facebook confirmed the outage but didn't divulge details .\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\"sentiment-analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.991114616394043},\n",
       " {'label': 'NEGATIVE', 'score': 0.991114616394043},\n",
       " {'label': 'NEGATIVE', 'score': 0.991114616394043}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp([summary_news,summary_news,summary_news])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list to RDD\n",
    "news_rdd = spark.sparkContext.parallelize(news_data)\n",
    "\n",
    "# Create data frame\n",
    "news_df = spark.createDataFrame(news_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_sentence_detector = sparknlp.annotators.DeepSentenceDetector() \\\n",
    "    .setInputCols([\"document\", \"token\", \"ner_con\"]) \\\n",
    "    .setOutputCol(\"sentence\") \\\n",
    "    .setIncludePragmaticSegmenter(True) \\\n",
    "    .setEndPunctuation([\".\", \"?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_df = news_df.select('news_content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_na_df = news_df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = content_df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html(input_string):\n",
    "    cleaned_text = BeautifulSoup(input_string).text\n",
    "    return cleaned_text\n",
    "\n",
    "strip_html_udf = udf(strip_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = drop_na_df.select('news_content', strip_html_udf('news_content').alias('clean_content'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/introduction-to-spark-nlp-foundations-and-basic-components-part-i-c83b7629ed59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp import DocumentAssembler\n",
    "\n",
    "from sparknlp.annotator import SentenceDetector, DeepSentenceDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "document_assembler = DocumentAssembler()\\\n",
    "                        .setInputCol(\"clean_content\")\\\n",
    "                        .setOutputCol(\"document\")\n",
    "\n",
    "sentenceDetector = SentenceDetector()\\\n",
    "                     .setInputCols([\"document\"])\\\n",
    "                     .setOutputCol(\"sentences\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "document_assembler = DocumentAssembler()\\\n",
    "                        .setInputCol(\"clean_content\")\\\n",
    "                        .setOutputCol(\"document\")\n",
    "\n",
    "sentenceDetector = DeepSentenceDetector()\\\n",
    "                     .setInputCols([\"document\"])\\\n",
    "                     .setOutputCol(\"sentences\")\\\n",
    "                     .setIncludePragmaticSegmenter(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpPipeline = Pipeline(stages=[\n",
    " document_assembler, \n",
    " sentenceDetector,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_sentences = nlpPipeline.fit(clean_df).transform(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- news_content: string (nullable = true)\n",
      " |-- clean_content: string (nullable = true)\n",
      " |-- document: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- sentences: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "content_sentences.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_collect = content_sentences.select('sentences').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(document, 0, 44, Apple  News is getting a si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(document, 0, 172, More than 2,500 mobile gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(document, 0, 250, (Bloomberg) -- The Twitter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(document, 0, 173, (Bloomberg) -- It wasn’t m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(document, 0, 135, (Bloomberg) -- TikTok has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>[(document, 0, 481, Netflix NFLX is set to rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>[(document, 0, 150, Netflix NFLX has landed th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>[(document, 0, 291, The Walt Disney Company (N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>[(document, 1, 36, Click here to read the full...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>[(document, 0, 27, In light of Caterpillar Inc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentences\n",
       "0    [(document, 0, 44, Apple  News is getting a si...\n",
       "1    [(document, 0, 172, More than 2,500 mobile gam...\n",
       "2    [(document, 0, 250, (Bloomberg) -- The Twitter...\n",
       "3    [(document, 0, 173, (Bloomberg) -- It wasn’t m...\n",
       "4    [(document, 0, 135, (Bloomberg) -- TikTok has ...\n",
       "..                                                 ...\n",
       "148  [(document, 0, 481, Netflix NFLX is set to rep...\n",
       "149  [(document, 0, 150, Netflix NFLX has landed th...\n",
       "150  [(document, 0, 291, The Walt Disney Company (N...\n",
       "151  [(document, 1, 36, Click here to read the full...\n",
       "152  [(document, 0, 27, In light of Caterpillar Inc...\n",
       "\n",
       "[153 rows x 1 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row_list = sentences_collect.iloc[0,:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first_row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple  News is getting a significant upgrade.',\n",
       " 'The news aggregation app, which ships preinstalled on Apple devices, is introducing several new features for readers and premium subscribers, including audio stories, a daily audio briefing called \"Apple News Today\" and expanded local coverage.',\n",
       " \"The audio briefing is somewhat of a competitor to Alexa's Flash Briefing, which has become a popular way to catch up on the top news headlines.\",\n",
       " \"But in Apple's case, the briefing is hosted by people, not a virtual assistant.\",\n",
       " \"Apple News editors and co-hosts, Shumita Basu and Duarte Geraldino, will guide listeners through the day's headlines.\",\n",
       " 'They will then spend the remainder of the briefing discussing around three or four articles in a more in-depth fashion.',\n",
       " 'Image Credits: Apple\\n\\n\\nIn total, the briefing will run for roughly seven to eight minutes in length and will be accessible to all Apple News readers in the U.S.',\n",
       " 'A new briefing will arrive every Monday through Friday, and can be played in the Apple News app in the U.S., in Apple Podcasts, or it can be launched using Siri voice commands across Apple devices, including Mac and HomePod.',\n",
       " 'Another new audio feature, audio stories, is only being made available to Apple News+ subscribers, however.',\n",
       " 'Starting today, Apple News will produce around 20 new audio stories per week across a range of topics, which are narrated by voice actors.',\n",
       " \"These stories aren't original content, but will instead be professionally narrated versions of feature reporting and other long-form pieces published by Essence, Esquire, Fast Company, GQ, New York Magazine, Sports Illustrated, TIME, Vanity Fair, Vogue, Wired and others, as well as newspapers like The Wall Street Journal and the Los Angeles Times.\",\n",
       " 'Image Credits: Apple\\n\\nApple several years ago had partnered with SpokenLayer to bring audio narration to the news, but that effort was focused on enhancing the Apple Podcasts experience.',\n",
       " \"The company says it's not partnered with SpokenLayer on the new feature for Apple News, but is instead working with voice talent itself and recording these audio stories in its own studios.\",\n",
       " 'Apple declined to say how many have been hired to work on audio programming for Apple News, but did confirm it expanded headcount specifically for audio.',\n",
       " 'The audio stories will be made available to subscribers in the U.S. only.',\n",
       " \"Apple didn't say if it's planning to expand the offering to international markets.\",\n",
       " 'To make room for the new audio features, the Apple News app navigation experience has been redesigned.',\n",
       " 'There\\'s now an \"Audio\" tab directing users to the new content at the bottom of the news application, in between the \"News+\" and \"Following\" tabs at the bottom of the screen.',\n",
       " \"When tapped, users will first see the latest episode of Apple News Today at the top of the screen, followed by the new Audio Stories that you've added to your Up Next queue.\",\n",
       " 'Below that will be a set of personalized recommendations of what to listen to next.',\n",
       " \"While the tab organizes the new audio programming, users will also be introduced to audio as they're browsing elsewhere in the app.\",\n",
       " \"For example, as you're scrolling through news stories in the Today tab or reading News+ feeds, a new audio News+ badge will appear next to stories that have narration.\",\n",
       " 'You can then click that story to begin the narration without having to change screens.',\n",
       " 'The feature will also allow you to transition back and forth between reading and listening as it will remember where you left off in a longer piece, and begin there when you return.',\n",
       " 'Related to these efforts, CarPlay will support the News app so users can listen to these audio stories and the Apple News Today briefing while driving.',\n",
       " 'Listening progress will also sync between devices, as you move from iPhone to car and back again.',\n",
       " 'Image Credits: Apple\\n\\nWhile the big news today is the audio programming coming to Apple News, the app is also today introducing expanded local coverage.',\n",
       " 'In select markets -- San Francisco and the wider Bay Area, New York, LA and Houston -- Apple News will feature a curated local news experience headed by a local editor.',\n",
       " 'These sections will include a wider range of stories across areas like local weather, politics, sports, dining and restaurants, and other news, and will be personalized to each reader.',\n",
       " \"Apple News rival Flipboard recently launched a similar feature to capitalize on the growing demand for local news, particularly amid the coronavirus pandemic where readers need access to their city and state's reports of the impact of COVID-19 on their daily lives.\",\n",
       " 'Image Credits: Apple\\n\\nApple News+ also today expanded its selection of local and regional newspapers to now offer access to The Charlotte Observer, The Idaho Statesman, The Kansas City Star, the Miami Herald, The News & Observer (Raleigh, NC) and The State (Columbia, SC) in the U.S.',\n",
       " 'In Canada it added French-language newspaper Le Devoir and will bring on The Globe and Mail later this summer.',\n",
       " 'While the Apple News platform currently reaches over 125 million monthly active users in the U.S., U.K.',\n",
       " 'Australia and Canada, the uptake on the News+ subscription has reportedly seen struggles in terms of growing its paid subscriber base.',\n",
       " \"Earlier this year, Apple's News service business chief, Liz Schimel, who managed relationship with publishers and advertisers, stepped down after the subscription service's slow start, Bloomberg reported.\",\n",
       " 'Publishers participating in Apple News+ keep 100% of the revenue from ads they sell and can participate in backfill ads that Apple sells, keeping 70% of the revenue.',\n",
       " 'They can also sell their own subscriptions and receive a cut of Apple News+ revenue, based on engagement.',\n",
       " 'But not all publishers believe Apple News+ is the best way to grow their business.',\n",
       " 'The New York Times, for example, announced in June it will no longer distribute articles in the Apple News app.',\n",
       " \"Despite the reports, Apple says it's pleased with Apple News+ traction.\",\n",
       " \"But today's new features are clearly designed to spark growth for the $9.99 per month paid subscription.\",\n",
       " 'The new Apple News features will come by way of software updates ( iOS 13.6, iPadOS 13.6, or macOS 10.15.6), arriving today.',\n",
       " '[gallery ids=\"2017175,2017171,2017166,2017168,2017167,2017164,2017165,2017160,2017157,2017156,2017152,2017173\"]\\n(Image credits: Apple)']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[row['result'] for row in first_row_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpack the list of sentence finder results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_sentences_df = content_sentences.select('sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences.result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Apple  News is getting a significant upgrade....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[More than 2,500 mobile games have been remove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(Bloomberg) -- The Twitter accounts of some o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(Bloomberg) -- It wasn’t meant to be like thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(Bloomberg) -- TikTok has become one of the w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>[Netflix NFLX is set to report second-quarter ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>[Netflix NFLX has landed the new romantic come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>[The Walt Disney Company (NYSE:DIS), a global ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>[Click here to read the full article., The “wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>[In light of Caterpillar Inc., (NYSE:CAT) prop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      sentences.result\n",
       "0    [Apple  News is getting a significant upgrade....\n",
       "1    [More than 2,500 mobile games have been remove...\n",
       "2    [(Bloomberg) -- The Twitter accounts of some o...\n",
       "3    [(Bloomberg) -- It wasn’t meant to be like thi...\n",
       "4    [(Bloomberg) -- TikTok has become one of the w...\n",
       "..                                                 ...\n",
       "148  [Netflix NFLX is set to report second-quarter ...\n",
       "149  [Netflix NFLX has landed the new romantic come...\n",
       "150  [The Walt Disney Company (NYSE:DIS), a global ...\n",
       "151  [Click here to read the full article., The “wa...\n",
       "152  [In light of Caterpillar Inc., (NYSE:CAT) prop...\n",
       "\n",
       "[153 rows x 1 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_sentences_df.select(found_sentences_df.sentences.getField(\"result\")).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "df2 = found_sentences_df.select(found_sentences_df.name,explode(df.knownLanguages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try adding a UDF for transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html(input_string):\n",
    "    cleaned_text = BeautifulSoup(input_string).text\n",
    "    return cleaned_text\n",
    "\n",
    "strip_html_udf = udf(strip_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9305248856544495}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentimentAnalysis = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "\n",
    "\n",
    "print(sentimentAnalysis(\"Transformers piplines are easy to use\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentimentAnalysis(\"Big Tech Stocks Top Trillion-Dollar Each: ETFs to Bet On\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import sparknlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparknlp.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "    .appName(\"Spark NLP\") # Set app name\n",
    "    .master(\"local[4]\") # Run locally with 4 cores\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.5.3s\") # configure spark nlp\n",
    "#     .config(\"spark.driver.memory\",\"16G\")\n",
    "#     .config(\"spark.driver.maxResultSize\", \"0\") \n",
    "#     .config(\"spark.kryoserializer.buffer.max\", \"1000M\")\n",
    "    .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faangs_venv",
   "language": "python",
   "name": "faangs_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
